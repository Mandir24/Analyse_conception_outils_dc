#*************************************************************************#
# Auteur : DIOP MANDIR
# Date : Script de nettoyage et pr√©paration des donn√©es
#*************************************************************************#
"""
Script de pr√©paration des donn√©es des fichiers de donn√©es, 
notamment 'statistiques_pays_du_monde.csv' et
'Classement_THE_des_universites_mondiales_2016‚Äì2025.csv'.
"""
#===============================================================#
#================ Importation des biblioth√®ques ================#
#===============================================================#
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import logging
import os
from datetime import datetime

#===============================================================#
#================ Configuration du logging =====================#
#===============================================================#
def configurer_logger():
    """Configure le syst√®me de logging avec fichier et console."""
    # Cr√©er le dossier logs s'il n'existe pas
    if not os.path.exists('logs'):
        os.makedirs('logs')
    
    # Nom du fichier de log avec timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_filename = f'logs/preparation_donnees_{timestamp}.log'
    
    # Configuration du logger
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    
    # Format des messages
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Handler pour fichier
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    
    # Handler pour console
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    # Ajouter les handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

#===============================================================#
#================ Fonctions de traitement ======================#
#===============================================================#
def charger_fichier_csv(chemin, description, logger):
    """Charge un fichier CSV avec gestion d'erreurs."""
    logger.info(f"Lecture du fichier {description}...")
    print(f"\n Lecture du fichier {description}...")
    
    try:
        df = pd.read_csv(chemin)
        logger.info(f"‚úì Fichier charg√© avec succ√®s : {len(df)} lignes, {len(df.columns)} colonnes")
        print(f"  ‚úì Fichier charg√© avec succ√®s")
        print(f"    Lignes : {len(df)} | Colonnes : {len(df.columns)}")
        return df
    except FileNotFoundError:
        logger.error(f"‚úó Fichier introuvable : {chemin}")
        print(f"  ‚úó ERREUR : Fichier '{chemin}' introuvable")
        raise
    except PermissionError:
        logger.error(f"‚úó Permission refus√©e pour : {chemin}")
        print(f"  ‚úó ERREUR : Permission refus√©e. Fermez le fichier s'il est ouvert.")
        raise
    except Exception as e:
        logger.error(f"‚úó Erreur lors du chargement : {str(e)}")
        print(f"  ‚úó ERREUR : {str(e)}")
        raise

def traiter_fichier_pays(df, logger):
    """Traite le fichier des statistiques pays."""
    logger.info("=== D√âBUT TRAITEMENT FICHIER PAYS ===")
    
    # 1. Conversion des colonnes num√©riques
    logger.info("Conversion des colonnes num√©riques...")
    print("\n Conversion des colonnes num√©riques...")
    
    cols_a_convert = [
        "Pop. Density (per sq. mi.)", "Coastline (coast/area ratio)",
        "Net migration", "Infant mortality (per 1000 births)",
        "Literacy (%)", "Phones (per 1000)", "Arable (%)",
        "Crops (%)", "Other (%)", "Birthrate", "Deathrate",
        "Agriculture", "Industry", "Service"
    ]
    
    for col in cols_a_convert:
        try:
            df[col] = df[col].str.replace(",", ".", regex=False).astype(float)
        except Exception as e:
            logger.warning(f"Probl√®me conversion colonne {col}: {e}")
    
    logger.info("‚úì Conversion termin√©e")
    print("  ‚úì Conversion termin√©e")
    
    # 2. V√©rification des doublons
    logger.info("V√©rification des doublons...")
    print("\n V√©rification des doublons...")
    nb_doublons = df.duplicated().sum()
    logger.info(f"Nombre de doublons trouv√©s : {nb_doublons}")
    print(f"  ‚úì Doublons d√©tect√©s : {nb_doublons}")
    
    # 3. S√©lection des colonnes
    logger.info("S√©lection des colonnes pertinentes...")
    print("\n S√©lection des colonnes pertinentes...")
    
    cols_a_garder = [
        "Country", "Region", "Area (sq. mi.)", "Population",
        "Net migration", "GDP ($ per capita)", "Literacy (%)",
        "Phones (per 1000)", "Industry", "Service"
    ]
    
    df = df[cols_a_garder]
    logger.info(f"{len(cols_a_garder)} colonnes conserv√©es")
    print(f"  ‚úì {len(cols_a_garder)} colonnes conserv√©es")
    
    # 4. Gestion des valeurs nulles
    logger.info("Gestion des valeurs nulles...")
    print("\nüßπ Gestion des valeurs nulles...")
    
    cols_isna = ["Net migration", "GDP ($ per capita)", "Literacy (%)",
                 "Phones (per 1000)", "Industry", "Service"]
    
    for col in cols_isna:
        nb_na = df[col].isna().sum()
        if nb_na > 0:
            logger.warning(f"Valeurs manquantes dans {col}: {nb_na}")
            print(f"    - {col}: {nb_na} valeurs manquantes")
            df[col] = df[col].fillna(df[col].median())
    
    logger.info("‚úì Valeurs nulles trait√©es")
    print("  ‚úì Valeurs nulles remplies avec la m√©diane")
    
    # 5. Nettoyage des espaces
    logger.info("Nettoyage des espaces...")
    print("\n‚úÇÔ∏è  Nettoyage des espaces...")
    
    cols_str = ["Country", "Region"]
    for col in cols_str:
        df[col] = df[col].astype(str).str.strip()
    
    logger.info("‚úì Espaces supprim√©s")
    print("  ‚úì Espaces supprim√©s")
    
    # 6. Renommage des colonnes
    logger.info("Renommage des colonnes...")
    print("\n  Renommage des colonnes...")
    
    df.rename(columns={
        "Country": "pays",
        "Region": "region",
        "Area (sq. mi.)": "superf_m2",
        "Population": "population",
        "Net migration": "migration_nette",
        "GDP ($ per capita)": "pib_hab",
        "Literacy (%)": "alphabetisation_pct",
        "Phones (per 1000)": "tel_1000hab",
        "Industry": "industrie_part",
        "Service": "services_part"
    }, inplace=True)
    
    logger.info("‚úì Colonnes renomm√©es")
    print("  ‚úì Colonnes renomm√©es")
    
    logger.info("=== FIN TRAITEMENT FICHIER PAYS ===")
    return df

def extraire_ratios(valeur):
    """
    Extrait ratio femme/homme.
    Retourne : (ratio_fem_pct, ratio_hom_pct)
    """
    if pd.isnull(valeur) or valeur == '':
        return None, None
    
    try:
        valeur_str = str(valeur).strip()
        
        # Format d√©cimal (0.45)
        if valeur_str.replace('.', '', 1).isdigit():
            dec = float(valeur_str)
            if 0 <= dec <= 1:
                fem = round(dec * 100, 2)
                hom = round(100 - fem, 2)
                return fem, hom
        
        # Format "45:55"
        if ":" in valeur_str:
            parts = valeur_str.split(':')
            if len(parts) >= 2:
                fem = float(parts[0])
                hom = float(parts[1])
                total = fem + hom
                if total > 0:
                    fem_pct = round(fem / total * 100, 2)
                    hom_pct = round(100 - fem_pct, 2)
                    return fem_pct, hom_pct
    except:
        pass
    
    return None, None

def detecter_valeurs_aberrantes(df, colonne, logger):
    """D√©tecte les valeurs aberrantes avec la m√©thode IQR."""
    Q1 = df[colonne].quantile(0.25)
    Q3 = df[colonne].quantile(0.75)
    IQR = Q3 - Q1
    seuil_bas = Q1 - 1.5 * IQR
    seuil_haut = Q3 + 1.5 * IQR
    
    aberrantes = df[(df[colonne] < seuil_bas) | (df[colonne] > seuil_haut)]
    
    if len(aberrantes) > 0:
        logger.info(f"Outliers d√©tect√©s dans {colonne}: {len(aberrantes)}")
    
    return aberrantes

def traiter_fichier_classement(data, logger):
    """Traite le fichier de classement THE."""
    logger.info("=== D√âBUT TRAITEMENT FICHIER CLASSEMENT ===")
    
    # 1. Correction des types
    logger.info("Correction des types de donn√©es...")
    print("\n Correction des types de donn√©es...")
    
    data['International Students'] = data['International Students'].str.replace('%', '', regex=False)
    
    def convertion_colonne_int(colonne):
        return pd.to_numeric(colonne, errors='coerce').astype('Int64')
    
    liste_colonnes_int = ['Rank', 'Student Population', 'Year']
    for col in liste_colonnes_int:
        data[col] = convertion_colonne_int(data[col])
    
    logger.info("‚úì Types corrig√©s")
    print("  ‚úì Types corrig√©s")
    
    # 2. Extraction des ratios
    logger.info("Extraction des ratios Femme/Homme...")
    print("\n Extraction des ratios Femme/Homme...")
    
    # Extraction des ratios
    data[['ratio_fem', 'ratio_hom']] = data['Female to Male Ratio'].apply(
        lambda x: pd.Series(extraire_ratios(x))
    )
    
    # Calcul du ratio fem/hom
    data['ratio_fem_hom'] = data.apply(
        lambda row: round(row['ratio_fem'] / row['ratio_hom'], 2)
        if pd.notnull(row['ratio_fem']) and pd.notnull(row['ratio_hom']) and row['ratio_hom'] != 0
        else None,
        axis=1
    )
    
    # Suppression de la colonne originale Female to Male Ratio
    data = data.drop(columns=['Female to Male Ratio'])
    
    logger.info("‚úì Ratios extraits")
    print("  ‚úì Ratios extraits (ratio_fem, ratio_hom, ratio_fem_hom conserv√©s)")
    print("  ‚úì Colonne 'Female to Male Ratio' supprim√©e")
    
    # 3. Renommage
    logger.info("Renommage des colonnes...")
    print("\n  Renommage des colonnes...")
    
    noms_colonnes = {
        'Rank': 'rang',
        'Name': 'nom_univ',
        'Country': 'pays',
        'Student Population': 'pop_etud',
        'Students to Staff Ratio': 'ratio_etud_pers',
        'International Students': 'etud_internationaux_pct',
        'Overall Score': 'score_global',
        'Teaching': 'indic_enseig',
        'Research Environment': 'indic_env_rech',
        'Research Quality': 'indic_qualite_rech',
        'Industry Impact': 'indic_impact_industrie',
        'International Outlook': 'indic_rel_intern',
        'Year': 'annee'
    }
    data.rename(columns=noms_colonnes, inplace=True)
    
    logger.info("‚úì Colonnes renomm√©es")
    print("  ‚úì Colonnes renomm√©es")
    
    # 4. D√©tection des outliers
    logger.info("D√©tection des outliers...")
    print("\n D√©tection des outliers (M√©thode IQR)...")
    
    colonnes_numeriques = [
        'rang', 'pop_etud', 'ratio_etud_pers', 'score_global',
        'indic_enseig', 'indic_env_rech', 'indic_qualite_rech',
        'indic_impact_industrie', 'indic_rel_intern'
    ]
    
    for col in colonnes_numeriques:
        aberrantes = detecter_valeurs_aberrantes(data, col, logger)
        print(f"    - {col}: {len(aberrantes)} outliers")
    
    logger.info("‚úì D√©tection termin√©e")
    print("  ‚úì D√©tection termin√©e")
    
    logger.info("=== FIN TRAITEMENT FICHIER CLASSEMENT ===")
    return data

def analyser_et_fusionner_donnees(data_pays, data_classement, logger):
    """Analyse les diff√©rences et fusionne les donn√©es."""
    logger.info("=== D√âBUT ANALYSE ET FUSION ===")
    
    # 1. Mapping des pays
    logger.info("Application du mapping des pays...")
    print("\n  Mapping des pays...")
    
    mapping_pays = {
        'Bosnia & Herzegovina': 'Bosnia and Herzegovina',
        'Brunei': 'Brunei Darussalam',
        'Congo, Dem. Rep.': 'Democratic Republic of the Congo',
        'Korea, South': 'South Korea',
        'Macau': 'Macao',
        'Macedonia': 'North Macedonia',
        'Russia': 'Russian Federation',
        'Gaza Strip': 'Palestine',
        'West Bank': 'Palestine',
    }
    
    data_pays['pays'] = data_pays['pays'].replace(mapping_pays)
    logger.info("‚úì Mapping appliqu√©")
    print("  ‚úì Mapping appliqu√©")
    
    # 2. Suppression des doublons
    logger.info("V√©rification des doublons...")
    print("\n V√©rification des doublons...")
    
    doublons = data_pays['pays'].value_counts()
    nb_doublons = len(doublons[doublons > 1])
    
    if nb_doublons > 0:
        logger.warning(f"{nb_doublons} pays en double d√©tect√©s")
        print(f"    {nb_doublons} pays en double d√©tect√©s")
        data_pays_clean = data_pays.drop_duplicates(subset=['pays'])
        logger.info("Doublons supprim√©s")
        print(f"  ‚úì Doublons supprim√©s")
    else:
        data_pays_clean = data_pays
        logger.info("Aucun doublon")
        print("  ‚úì Aucun doublon d√©tect√©")
    
    # 3. Analyse des pays
    logger.info("Analyse des pays communs et manquants...")
    print("\n Analyse des pays communs et manquants...")
    
    pays_classement = set(data_classement['pays'].dropna().unique())
    pays_data = set(data_pays_clean['pays'].dropna().unique())
    pays_manquants_data = pays_classement - pays_data
    pays_communs = pays_classement & pays_data
    
    logger.info(f"Pays dans classement: {len(pays_classement)}")
    logger.info(f"Pays dans data_pays: {len(pays_data)}")
    logger.info(f"Pays en commun: {len(pays_communs)}")
    print(f"  ‚Ä¢ Pays classement: {len(pays_classement)}")
    print(f"  ‚Ä¢ Pays data_pays: {len(pays_data)}")
    print(f"  ‚Ä¢ Pays communs: {len(pays_communs)}")
    
    if pays_manquants_data:
        logger.warning(f"{len(pays_manquants_data)} pays manquants dans data_pays")
        print(f"\n‚ö†Ô∏è  Pays manquants dans data_pays ({len(pays_manquants_data)}):")
        for pays in sorted(pays_manquants_data):
            nb_univ = len(data_classement[data_classement['pays'] == pays])
            logger.warning(f"  - {pays}: {nb_univ} universit√©(s)")
            print(f"     ‚Ä¢ {pays} ({nb_univ} universit√©(s))")
    
    # 4. Fusion
    logger.info("Fusion des dataframes...")
    print("\nüîó Fusion des donn√©es...")
    
    data_final = data_classement.merge(
        data_pays_clean,
        on='pays',
        how='left',
        suffixes=('', '_pays')
    )
    
    logger.info(f"Fusion effectu√©e: {len(data_final)} lignes")
    print(f"  ‚úì Fusion effectu√©e: {len(data_final)} lignes")
    
    # 5. Traitement des r√©gions manquantes
    logger.info("Traitement des r√©gions manquantes...")
    print("\n Traitement des r√©gions manquantes...")
    
    if 'region' in data_final.columns:
        nb_manquantes = data_final['region'].isna().sum()
        logger.info(f"R√©gions manquantes: {nb_manquantes}")
        print(f"  ‚Ä¢ R√©gions manquantes: {nb_manquantes}")
        
        data_final['region'] = data_final['region'].fillna('Inconnu')
        data_final['region'] = data_final['region'].replace(['', ' '], 'Inconnu')
        
        logger.info("‚úì R√©gions trait√©es")
        print("  ‚úì R√©gions trait√©es")
    
    logger.info("=== FIN ANALYSE ET FUSION ===")
    return data_pays_clean, data_final, pays_manquants_data

def sauvegarder_fichiers(data_pays, data_classement, data_final, pays_manquants, logger):
    """Sauvegarde tous les fichiers de sortie."""
    logger.info("=== D√âBUT SAUVEGARDE FICHIERS ===")
    print("\n Sauvegarde des fichiers...")
    
    fichiers_sauvegardes = []
    
    try:
        # Cr√©er le dossier si n√©cessaire
        os.makedirs('data', exist_ok=True)
        
        # 1. data_pays.csv
        chemin = 'data/data_pays.csv'
        data_pays.to_csv(chemin, index=False)
        logger.info(f"‚úì Fichier sauvegard√©: {chemin}")
        print(f"  ‚úì {chemin}")
        fichiers_sauvegardes.append(chemin)
        
        # 2. Classement nettoy√©
        chemin = 'data/Classement_THE_nettoye.csv'
        data_classement.to_csv(chemin, index=False)
        logger.info(f"‚úì Fichier sauvegard√©: {chemin}")
        print(f"  ‚úì {chemin}")
        fichiers_sauvegardes.append(chemin)
        
        # 3. data_final_fusionne.csv
        chemin = 'data/data_final_fusionne.csv'
        data_final.to_csv(chemin, index=False)
        logger.info(f"‚úì Fichier sauvegard√©: {chemin}")
        print(f"  ‚úì {chemin}")
        fichiers_sauvegardes.append(chemin)
        
        # 4. Rapport pays manquants
        if pays_manquants:
            detail_manquants = []
            for pays in sorted(pays_manquants):
                universites = data_classement[data_classement['pays'] == pays]['nom_univ'].tolist()
                detail_manquants.append({
                    'pays': pays,
                    'nb_universites': len(universites),
                    'universites': ' | '.join(universites)
                })
            
            df_detail = pd.DataFrame(detail_manquants)
            chemin = 'data/detail_pays_manquants.csv'
            df_detail.to_csv(chemin, index=False)
            logger.info(f"‚úì Fichier sauvegard√©: {chemin}")
            print(f"  ‚úì {chemin}")
            fichiers_sauvegardes.append(chemin)
        
        logger.info(f"=== FIN SAUVEGARDE: {len(fichiers_sauvegardes)} fichiers ===")
        return fichiers_sauvegardes
        
    except Exception as e:
        logger.error(f"Erreur lors de la sauvegarde: {str(e)}")
        print(f"  ‚úó ERREUR: {str(e)}")
        raise

#===============================================================#
#===================== FONCTION MAIN ===========================#
#===============================================================#
def main():
    """Fonction principale du script."""
    # Configuration du logger
    logger = configurer_logger()
    
    logger.info("="*70)
    logger.info("D√âMARRAGE DU SCRIPT DE NETTOYAGE DES DONN√âES")
    logger.info("="*70)
    
    print("\n" + "="*70)
    print("  SCRIPT DE NETTOYAGE ET PR√âPARATION DES DONN√âES")
    print("="*70)
    
    try:
        # PARTIE 1 : Traitement fichier pays
        logger.info("\n### PARTIE 1: TRAITEMENT FICHIER PAYS ###")
        print("\n" + "="*70)
        print("PARTIE 1 : TRAITEMENT FICHIER PAYS")
        print("="*70)
        
        df_pays = charger_fichier_csv(
            "data/statistiques_pays_du_monde.csv",
            "statistiques_pays_du_monde.csv",
            logger
        )
        df_pays = traiter_fichier_pays(df_pays, logger)
        
        # PARTIE 2 : Traitement fichier classement
        logger.info("\n### PARTIE 2: TRAITEMENT FICHIER CLASSEMENT ###")
        print("\n" + "="*70)
        print("PARTIE 2 : TRAITEMENT FICHIER CLASSEMENT THE")
        print("="*70)
        
        df_classement = charger_fichier_csv(
            "data/Classement_THE_des_universites_mondiales_2016‚Äì2025.csv",
            "Classement THE 2016-2025",
            logger
        )
        df_classement = traiter_fichier_classement(df_classement, logger)
        
        # PARTIE 3 : Analyse et fusion
        logger.info("\n### PARTIE 3: ANALYSE ET FUSION ###")
        print("\n" + "="*70)
        print("PARTIE 3 : ANALYSE ET FUSION DES DONN√âES")
        print("="*70)
        
        df_pays_clean, df_final, pays_manquants = analyser_et_fusionner_donnees(
            df_pays, df_classement, logger
        )
        
        # PARTIE 4 : Sauvegarde
        logger.info("\n### PARTIE 4: SAUVEGARDE ###")
        print("\n" + "="*70)
        print("PARTIE 4 : SAUVEGARDE DES FICHIERS")
        print("="*70)
        
        fichiers = sauvegarder_fichiers(
            df_pays_clean, df_classement, df_final, pays_manquants, logger
        )
        
        # Statistiques finales
        print("\n" + "="*70)
        print(" STATISTIQUES FINALES")
        print("="*70)
        print(f"\n  R√©partition par r√©gion:")
        regions = df_final['region'].value_counts()
        for region, count in regions.items():
            print(f"    ‚Ä¢ {region}: {count} universit√©s")
        
        logger.info("="*70)
        logger.info("‚úì SCRIPT TERMIN√â AVEC SUCC√àS")
        logger.info("="*70)
        
        print("\n" + "="*70)
        print(" SCRIPT TERMIN√â AVEC SUCC√àS")
        print("="*70)
        print(f"\n {len(fichiers)} fichiers g√©n√©r√©s")
        print(f" Log sauvegard√© dans le dossier 'logs/'")
        print("="*70 + "\n")
        
    except Exception as e:
        logger.error(f"ERREUR CRITIQUE: {str(e)}", exc_info=True)
        print(f"\n ERREUR CRITIQUE: {str(e)}")
        print("Consultez le fichier de log pour plus de d√©tails.")
        raise

#===============================================================#
#=================== POINT D'ENTR√âE ============================#
#===============================================================#
if __name__ == "__main__":
    main()